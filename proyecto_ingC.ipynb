{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scrapping IMSSS\n",
    "### Web Scrapping de la página general por años"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_url = \"http://datos.imss.gob.mx\"\n",
    "r = requests.get(\"http://datos.imss.gob.mx/dataset\")\n",
    "soup = BeautifulSoup(r.content, \"html.parser\") \n",
    "spans = soup.find_all(\"a\", {'data-format':'csv'}, href=True)\n",
    "links = []\n",
    "for link in spans:\n",
    "    href = link.get(\"href\")\n",
    "    if '/dataset/asg-' in href:\n",
    "        condicion = int(re.findall(r'\\d{4}', href)[0])\n",
    "        if condicion >= 2018 and condicion < 2023:\n",
    "            links.append(base_url + href)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scrapping pt 2 por meses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "links_2 = []\n",
    "for i in range(len(links)):\n",
    "    r_2 = requests.get(links[i])\n",
    "    soup_2 = BeautifulSoup(r_2.content, \"html.parser\")\n",
    "    spans_2 = soup_2.find_all(\"a\", {'property':'dcat:accessURL'}, href=True)\n",
    "    for link in spans_2:\n",
    "        links_2.append(base_url + link.get(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = []\n",
    "for i in range(len(links_2)):\n",
    "    r_3 = requests.get(links_2[i])\n",
    "    soup_3 = BeautifulSoup(r_3.content, \"html.parser\")\n",
    "    spans_3 = soup_3.find_all(\"a\", href=True)\n",
    "    for link in spans_3:\n",
    "        if '.csv' in link.get(\"href\"):\n",
    "            df.append(link.get(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crear un DataFrame vacío para almacenar los datos combinados\n",
    "df_combined = pd.DataFrame()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    # Leer el archivo CSV y especificar el tipo de datos adecuado (si es necesario)\n",
    "    df_csv = pd.read_csv(df[i], encoding=\"latin-1\", sep=\"|\", dtype={\"columna_con_tipo_mezclado\": str}, low_memory=False)\n",
    "\n",
    "    columns = ['rango_uma', 'ta', 'teu', 'tec', 'tpu', 'tpc',\n",
    "               'ta_sal', 'teu_sal', 'tec_sal', 'tpu_sal', 'tpc_sal', 'masa_sal_ta',\n",
    "               'masa_sal_teu', 'masa_sal_tec', 'masa_sal_tpu', 'masa_sal_tpc']\n",
    "\n",
    "    # Usar copy() para evitar SettingWithCopyWarning\n",
    "    df_sonora = df_csv.loc[(df_csv[\"sector_economico_1\"] == 0) & (df_csv[\"cve_entidad\"] == 26)].copy()\n",
    "\n",
    "    # Eliminar columnas\n",
    "    df_sonora.drop(columns, inplace=True, axis=1)\n",
    "\n",
    "    # Extraer año y mes de la URL\n",
    "    df_sonora['año'] = re.findall(r'\\d{4}', df[i])[0]\n",
    "    df_sonora['mes'] = re.findall(r'-(\\d{2})-', df[i])[0]\n",
    "\n",
    "    # Filtrar por sector_economico_2\n",
    "    df_append = df_sonora[df_sonora[\"sector_economico_2\"].isin([1, 2, 4])]\n",
    "\n",
    "    # Usar pd.concat en lugar de append (sin ignore_index=True)\n",
    "    df_combined = pd.concat([df_combined, df_append])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# df_combined.to_csv('df_imss.csv') \n",
    "# files.download('df_imss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imss = pd.read_csv('df_imss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 629639 entries, 0 to 629638\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   Unnamed: 0          629639 non-null  int64  \n",
      " 1   cve_delegacion      629639 non-null  int64  \n",
      " 2   cve_subdelegacion   629639 non-null  int64  \n",
      " 3   cve_entidad         629639 non-null  int64  \n",
      " 4   cve_municipio       629639 non-null  object \n",
      " 5   sector_economico_1  629639 non-null  float64\n",
      " 6   sector_economico_2  629639 non-null  float64\n",
      " 7   sector_economico_4  629639 non-null  float64\n",
      " 8   tamaño_patron       628822 non-null  object \n",
      " 9   sexo                629639 non-null  int64  \n",
      " 10  rango_edad          629639 non-null  object \n",
      " 11  rango_salarial      628979 non-null  object \n",
      " 12  asegurados          629639 non-null  int64  \n",
      " 13  no_trabajadores     629639 non-null  int64  \n",
      " 14  año                 629639 non-null  int64  \n",
      " 15  mes                 629639 non-null  int64  \n",
      "dtypes: float64(3), int64(9), object(4)\n",
      "memory usage: 76.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_imss.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping Agricultura (2018-2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://datos.sonora.gob.mx/conjuntos-de-datos/mostrar/datos-de-agricultura-sonora/1573'\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "spans = soup.find_all(\"a\", href=True)\n",
    "\n",
    "# Lista de años\n",
    "years = ['2018', '2019', '2020', '2021', '2022']\n",
    "links_xlsx = []\n",
    "# Recorre la lista de años y busca enlaces con títulos que coincidan con cada año\n",
    "for year in years:\n",
    "    links = soup.find_all(\"a\", {'title': f'Producción agrícola {year}'}, href=True)\n",
    "    for link in links:\n",
    "        links_xlsx.append(link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agricultura = pd.DataFrame()\n",
    "for i in range(len(links_xlsx)):\n",
    "    df_agricultura = pd.concat([df_agricultura, pd.read_excel(links_xlsx[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agricultura.to_csv('df_agricultura.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7219 entries, 0 to 1453\n",
      "Data columns (total 16 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   ANO          7219 non-null   int64  \n",
      " 1   CIERREYAVAN  7219 non-null   object \n",
      " 2   CICLO        7219 non-null   int64  \n",
      " 3   CDDR         7219 non-null   int64  \n",
      " 4   NDDR         7219 non-null   object \n",
      " 5   CMUN         7219 non-null   int64  \n",
      " 6   NMUN         7219 non-null   object \n",
      " 7   CVECUL       7219 non-null   int64  \n",
      " 8   CULTIVO      7219 non-null   object \n",
      " 9   SUPSEM       7219 non-null   float64\n",
      " 10  SUPCOSE      7219 non-null   float64\n",
      " 11  SUPSINI      7219 non-null   float64\n",
      " 12  PRODTON      7219 non-null   float64\n",
      " 13  RENDMNTO     7219 non-null   float64\n",
      " 14  PMR          7052 non-null   float64\n",
      " 15  VALPROD      7219 non-null   float64\n",
      "dtypes: float64(7), int64(5), object(4)\n",
      "memory usage: 958.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_agricultura.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping Pecuaria (2018-2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL de la página HTML\n",
    "url = 'https://datos.sonora.gob.mx/conjuntos-de-datos/mostrar/datos-ganaderia-sonora/1581'\n",
    "\n",
    "# Realiza la solicitud HTTP\n",
    "r = requests.get(url)\n",
    "\n",
    "# Parsea el contenido HTML\n",
    "soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "# Lista de años\n",
    "years = ['2018', '2019', '2020', '2021', '2022']\n",
    "\n",
    "# Lista para almacenar los enlaces .xlsx\n",
    "links_xlsx = []\n",
    "\n",
    "# Expresión regular para buscar enlaces .xlsx\n",
    "xlsx_pattern = re.compile(r'\\.xlsx$')\n",
    "\n",
    "# Busca todos los enlaces con extensión .xlsx en la página\n",
    "enlaces = soup.find_all('a', href=xlsx_pattern)\n",
    "\n",
    "# Recorre los enlaces y verifica si el texto del enlace contiene un año de la lista\n",
    "for enlace in enlaces:\n",
    "    texto_enlace = enlace.text\n",
    "    for year in years:\n",
    "        if year in texto_enlace:\n",
    "            links_xlsx.append(enlace['href'])\n",
    "\n",
    "# Elimina duplicados (si los hay) utilizando set y luego convierte de nuevo a lista\n",
    "links_xlsx = list(set(links_xlsx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pecuaria = pd.DataFrame()\n",
    "for i in range(len(links_xlsx)):\n",
    "    df_pecuaria = pd.concat([df_pecuaria, pd.read_excel(links_xlsx[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1610 entries, 0 to 319\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   ANO        1610 non-null   int64  \n",
      " 1   CIERYAVAN  1610 non-null   object \n",
      " 2   CDDR       1610 non-null   int64  \n",
      " 3   NDDR       1610 non-null   object \n",
      " 4   CMUN       1610 non-null   int64  \n",
      " 5   NMUN       1610 non-null   object \n",
      " 6   CVEMES     1610 non-null   int64  \n",
      " 7   NMES       1610 non-null   object \n",
      " 8   CVESPE     1610 non-null   int64  \n",
      " 9   ESPECIE    1610 non-null   object \n",
      " 10  PRODUC     1610 non-null   object \n",
      " 11  UMED       1610 non-null   object \n",
      " 12  VOLTON     1610 non-null   float64\n",
      " 13  VALPROD    1610 non-null   float64\n",
      "dtypes: float64(2), int64(5), object(7)\n",
      "memory usage: 188.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_pecuaria.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pecuaria.to_csv('df_pecuaria.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping Pesca (2018-2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL de la página HTML\n",
    "url = 'https://datos.sonora.gob.mx/conjuntos-de-datos/mostrar/datos-pesca-sonora/1582'\n",
    "\n",
    "# Realiza la solicitud HTTP\n",
    "r = requests.get(url)\n",
    "\n",
    "# Parsea el contenido HTML\n",
    "soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "# Lista de años\n",
    "years = ['2018', '2019', '2020', '2021', '2022']\n",
    "\n",
    "# Lista para almacenar los enlaces .xlsx\n",
    "links_xlsx = []\n",
    "\n",
    "# Expresión regular para buscar enlaces .xlsx\n",
    "xlsx_pattern = re.compile(r'\\.xlsx$')\n",
    "\n",
    "# Busca todos los enlaces con extensión .xlsx en la página\n",
    "enlaces = soup.find_all('a', href=xlsx_pattern)\n",
    "\n",
    "# Recorre los enlaces y verifica si el texto del enlace contiene un año de la lista\n",
    "for enlace in enlaces:\n",
    "    texto_enlace = enlace.text\n",
    "    for year in years:\n",
    "        if year in texto_enlace:\n",
    "            links_xlsx.append(enlace['href'])\n",
    "\n",
    "# Elimina duplicados (si los hay) utilizando set y luego convierte de nuevo a lista\n",
    "links_xlsx = list(set(links_xlsx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pesca = pd.DataFrame()\n",
    "for i in range(len(links_xlsx)):\n",
    "    df_pesca = pd.concat([df_pesca, pd.read_excel(links_xlsx[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2018, 2019, 2022, 2021, 2020], dtype=int64)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pesca.ANO.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1244 entries, 0 to 245\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   ANO         1244 non-null   int64 \n",
      " 1   CDDR        1244 non-null   int64 \n",
      " 2   NDDR        1244 non-null   object\n",
      " 3   CMUN        1244 non-null   int64 \n",
      " 4   CVEOF       1244 non-null   int64 \n",
      " 5   NOFICINA    1244 non-null   object\n",
      " 6   CVOTRAS     1244 non-null   int64 \n",
      " 7   DOTRAS      1244 non-null   object\n",
      " 8   CESPE       1244 non-null   int64 \n",
      " 9   ESPECIE     1244 non-null   object\n",
      " 10  CVORIGEN    1244 non-null   int64 \n",
      " 11  ORIGEN      1244 non-null   object\n",
      " 12  PESODESEMB  1244 non-null   int64 \n",
      " 13  PVIVO       1244 non-null   int64 \n",
      " 14  VALOR       1244 non-null   int64 \n",
      "dtypes: int64(10), object(5)\n",
      "memory usage: 155.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_pesca.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pesca.to_csv('df_pesca.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
